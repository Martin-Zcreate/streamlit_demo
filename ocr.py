import streamlit as st
import base64
from openai import OpenAI
from PIL import Image

def get_img_str(file_path):
    with open(file_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

# ä½¿ç”¨ cache_data é¿å…é‡å¤è¯†åˆ«ï¼ŒèŠ‚çœ token ä¸”ä¼˜åŒ–ä½“éªŒ
@st.cache_data(show_spinner=False)
def get_ocr_text(file_content):
    # æ³¨æ„ï¼šst.cache_data å¯¹ bytes æ›´å‹å¥½ï¼Œæ‰€ä»¥ä¼ å…¥ content è€Œä¸æ˜¯ UploadedFile å¯¹è±¡
    a = "sk-vogujjwsiclsbtlaorwvnncwfidlxavtukoxcqlciakmhtkr"
    b = "deepseek-ai/DeepSeek-OCR"
    
    # å»ºç«‹è¿æ¥
    client = OpenAI(
        api_key=a,
        base_url="https://api.siliconflow.cn/v1"
    )

    try:
        # d: å›¾ç‰‡çš„ Base64 ç¼–ç 
        d = base64.b64encode(file_content).decode('utf-8')
        
        print(f"æ­£åœ¨å‘é€è¯·æ±‚ç»™æ¨¡å‹: {b} ...")

        # e: å‘é€è¯·æ±‚
        e = client.chat.completions.create(
            model=b,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¯·æå–å›¾ç‰‡ä¸­çš„æ–‡å­—å’Œæ•°å­¦å…¬å¼ã€‚é‡è¦è¦æ±‚ï¼š\n1. æ‰€æœ‰æ•°å­¦å…¬å¼ï¼ˆåŒ…æ‹¬ç®€å•çš„å˜é‡å¦‚x, yï¼‰å¿…é¡»åŒ…å«åœ¨ $ ç¬¦å·ä¸­ï¼ˆè¡Œå†…å…¬å¼ï¼‰æˆ– $$ ç¬¦å·ä¸­ï¼ˆç‹¬ç«‹å…¬å¼ï¼‰ã€‚\n2. ä¸è¦è¾“å‡ºä»»ä½• JSON æ ¼å¼æˆ– Markdown ä»£ç å—ï¼ˆå¦‚ ```jsonï¼‰ã€‚\n3. åªè¿”å›çº¯æ–‡æœ¬å†…å®¹ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{d}"}}
                    ]
                }
            ],
            temperature=0.1,
        )

        content = e.choices[0].message.content
        
        # å¢å¼ºçš„åå¤„ç†é€»è¾‘
        content = content.strip()
        
        # 1. å»é™¤å¯èƒ½å­˜åœ¨çš„ markdown ä»£ç å—åŒ…è£¹
        if content.startswith("```"):
            lines = content.split('\n')
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ¢è¡Œç¬¦ï¼Œé€šå¸¸ç¬¬ä¸€è¡Œæ˜¯ ```latex æˆ– ```json
            if len(lines) >= 2:
                # é‡æ–°ç»„åˆï¼Œå»æ‰ç¬¬ä¸€è¡Œå’Œæœ€åä¸€è¡Œ
                content = "\n".join(lines[1:-1])
        
        # 2. ä¸“é—¨å¤„ç†å¸¸è§çš„ JSON è¯¯åˆ¤ (è¯†åˆ«ä¸º "}" æˆ– "{" ... "}")
        if content.endswith("}"):
            # å°è¯•æŸ¥æ‰¾å¯¹åº”çš„ "{"
            start_index = content.find("{")
            if start_index != -1:
                # å¯èƒ½æ˜¯ JSONï¼Œå°è¯•æå– "content" æˆ– "text" å­—æ®µ
                import json
                try:
                    json_data = json.loads(content[start_index:])
                    if isinstance(json_data, dict):
                        # ä¼˜å…ˆå– content, text, result ç­‰å­—æ®µ
                        for key in ["content", "text", "result", "ocr_text"]:
                            if key in json_data:
                                content = json_data[key]
                                break
                except:
                    pass # è§£æå¤±è´¥å°±å½“åšæ™®é€šæ–‡æœ¬
        
        return content

    except Exception as err:
        st.error(f"OCRå‡ºé”™: {err}")
        return None

def AI(messages):
    client = OpenAI(api_key="sk-af6ba48dbd8a4d1fb0d036551b9bbdc3",
                    base_url="https://api.deepseek.com")
    
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        stream=True
    )
    return response

# ================= ç½‘é¡µç•Œé¢å¸ƒå±€ =================

st.set_page_config(page_title="æ™ºé…·AIä½œä¸šå¸®æ‰‹", page_icon="ğŸ¤–")
st.title("ğŸ¤–æ™ºé…·AIä½œä¸šå¸®æ‰‹")

# åˆå§‹åŒ– Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_topic" not in st.session_state:
    st.session_state.current_topic = None
if "last_uploaded_file_id" not in st.session_state:
    st.session_state.last_uploaded_file_id = None
if "need_first_response" not in st.session_state:
    st.session_state.need_first_response = False

st.markdown("""
<style>
/* ä¼˜åŒ–ä¸Šä¼ æŒ‰é’®æ ·å¼ */
div[data-testid="stFileUploader"] label {
    font-size: 1.1rem !important;
    font-weight: bold !important;
}
</style>
""", unsafe_allow_html=True)

st.info("ğŸ’¡ æç¤ºï¼šç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œç›´æ¥é€‰æ‹©ã€æ‹ç…§ã€‘æˆ–ã€ç›¸æœºã€‘ä»¥ä¸Šä¼ é¢˜ç›®ã€‚")

# 1. åªä¿ç•™ä¸Šä¼ /ç³»ç»Ÿç›¸æœºæ¨¡å¼
img_file = st.file_uploader(
    "ğŸ“¸ ç‚¹å‡»æ‹æ‘„é¢˜ç›®", 
    type=['jpg', 'png', 'jpeg'], 
    accept_multiple_files=False,
    key="uploader"
)

# å¤„ç†å›¾ç‰‡ä¸Šä¼ é€»è¾‘
if img_file:
    # ç®€å•çš„æ–‡ä»¶IDç”Ÿæˆï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¯æ–°æ–‡ä»¶
    file_content = img_file.getvalue()
    file_id = f"{img_file.name}_{img_file.size}"
    
    # å¦‚æœæ˜¯æ–°ä¸Šä¼ çš„æ–‡ä»¶ï¼Œè¿›è¡Œ OCR å’Œåˆå§‹åŒ–
    if file_id != st.session_state.last_uploaded_file_id:
        with st.spinner('æ­£åœ¨è¯†åˆ«é¢˜ç›®...'):
            ocr_result = get_ocr_text(file_content)
            
            if ocr_result:
                st.session_state.current_topic = ocr_result
                st.session_state.last_uploaded_file_id = file_id
                
                # åˆå§‹åŒ–æ–°çš„å¯¹è¯
                st.session_state.messages = [
                    {"role": "system", "content": """
                    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è€å¸ˆã€‚
                    1. å½“å­¦ç”Ÿé—®é—®é¢˜æ—¶ï¼Œä¸è¦ç›´æ¥ç»™å®Œæ•´ç­”æ¡ˆã€‚
                    2. è¯·ä½¿ç”¨"éš¾åº¦é™çº§"æ³•ï¼ŒæŠŠå¤æ‚çš„é¢˜ç›®æ‹†è§£æˆç®€å•çš„æ­¥éª¤ã€‚
                    3. å…ˆè§£é‡Šæ€è·¯ï¼Œå†è®©å­¦ç”Ÿå»æ€è€ƒé—®é¢˜ã€‚
                    4. å…¬å¼è¯·ä½¿ç”¨ LaTeX æ ¼å¼ï¼Œè¡Œå†…å…¬å¼ç”¨ $ åŒ…è£¹ï¼Œç‹¬ç«‹å…¬å¼ç”¨ $$ åŒ…è£¹ã€‚
                    """},
                    {"role": "user", "content": f"å­¦ç”Ÿå‘æ¥äº†è¿™é“é¢˜ï¼Œè¯·è®²è§£ï¼š\n{ocr_result}"}
                ]
                
                # æ ‡è®°éœ€è¦ç¬¬ä¸€æ¬¡å›å¤
                st.session_state.need_first_response = True
                # å¼ºåˆ¶åˆ·æ–°ä»¥æ˜¾ç¤ºæ–°çŠ¶æ€
                st.rerun()

# 2. æ˜¾ç¤ºè¯†åˆ«åˆ°çš„é¢˜ç›®ï¼ˆä¼˜åŒ–æ˜¾ç¤ºï¼‰
if st.session_state.current_topic:
    with st.expander("ğŸ“ æŸ¥çœ‹è¯†åˆ«åˆ°çš„é¢˜ç›®", expanded=True):
        # ä½¿ç”¨ markdown æ¸²æŸ“ LaTeX
        st.markdown(st.session_state.current_topic)

# 3. èŠå¤©ç•Œé¢
st.subheader("ğŸ‘¨â€ğŸ« è€å¸ˆè®²è§£ & ç­”ç–‘")

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    if msg["role"] == "system":
        continue
    if msg["role"] == "user" and "å­¦ç”Ÿå‘æ¥äº†è¿™é“é¢˜" in msg["content"]:
        continue 
        
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# å¤„ç†é¦–æ¬¡è‡ªåŠ¨å›å¤ (æµå¼)
if st.session_state.need_first_response:
    st.session_state.need_first_response = False
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        stream = AI(st.session_state.messages)
        for chunk in stream:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    st.rerun()

# åº•éƒ¨è¾“å…¥æ¡†
if prompt := st.chat_input("å“ªé‡Œä¸æ‡‚ï¼Ÿå¯ä»¥ç»§ç»­é—®è€å¸ˆ..."):
    # æ˜¾ç¤ºç”¨æˆ·æé—®
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # æ˜¾ç¤º AI å›å¤
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        stream = AI(st.session_state.messages)
        for chunk in stream:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})
