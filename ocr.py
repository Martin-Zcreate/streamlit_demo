import streamlit as st
import base64
import re
import io
import json
from PIL import Image, ImageOps
from openai import OpenAI

# ================= æ¢å¤ä½ çš„ API KEY =================
# ç¡…åŸºæµåŠ¨ Key (ç”¨äº OCR) - å¯¹åº”ä½ æä¾›çš„ç¬¬ä¸€ä¸ª Key
OCR_API_KEY = "sk-vogujjwsiclsbtlaorwvnncwfidlxavtukoxcqlciakmhtkr"
# DeepSeek Key (ç”¨äºå¯¹è¯) - å¯¹åº”ä½ æä¾›çš„ç¬¬äºŒä¸ª Key
CHAT_API_KEY = "sk-af6ba48dbd8a4d1fb0d036551b9bbdc3"

# ================= æ ¸å¿ƒæ¸…æ´—å·¥å…· (è§£å†³èŠ±æ‹¬å·é—®é¢˜) =================

def clean_text(text):
    """
    ç»ˆææ¸…æ´—å‡½æ•°ï¼š
    1. å»é™¤ JSON èŠ±æ‹¬å·åŒ…è£¹
    2. å»é™¤ Markdown ä»£ç å—
    3. ä¿®å¤ LaTeX æ ¼å¼
    """
    if not text:
        return ""

    text = text.strip()

    # --- 1. æš´åŠ›å»é™¤ JSON å¤–å£³ ---
    # å¦‚æœå†…å®¹ä»¥ ```json å¼€å¤´ï¼Œæˆ–è€…ä»¥ { å¼€å¤´ï¼Œå°è¯•è§£æ
    if text.startswith("```") or text.startswith("{"):
        # ç§»é™¤ markdown æ ‡è®°
        text = re.sub(r'^```(json)?', '', text, flags=re.MULTILINE)
        text = re.sub(r'```$', '', text, flags=re.MULTILINE)
        text = text.strip()
        
        # å°è¯•ä½œä¸º JSON è§£æ
        try:
            data = json.loads(text)
            # å¦‚æœè§£ææˆåŠŸï¼Œä¼˜å…ˆå– 'content' æˆ– 'text' å­—æ®µ
            if isinstance(data, dict):
                if "content" in data:
                    text = data["content"]
                elif "text" in data:
                    text = data["text"]
                # å¦‚æœæ˜¯å…¶ä»– keyï¼Œæ¯”å¦‚ {"result":...}, åªè¦æ˜¯å­—å…¸ä¸”åªæœ‰ä¸€ä¸ªå¤§ valueï¼Œå°±å–é‚£ä¸ª
                elif len(data) == 1:
                    text = list(data.values())[0]
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼ˆæ¯”å¦‚ JSON ä¸å®Œæ•´ï¼‰ï¼Œå°è¯•ç”¨æ­£åˆ™æå– content":"..." åé¢çš„å†…å®¹
            match = re.search(r'"content"\s*:\s*"(.*?)"', text, re.DOTALL)
            if match:
                text = match.group(1)
                # å¤„ç†è½¬ä¹‰å­—ç¬¦
                text = text.replace('\\n', '\n').replace('\\"', '"')

    # --- 2. ä¿®å¤ LaTeX æ ¼å¼ ---
    # å°† \[ \] æ›¿æ¢ä¸º $$
    text = re.sub(r'\\\[(.*?)\\\]', r'$$\1$$', text, flags=re.DOTALL)
    # å°† \( \) æ›¿æ¢ä¸º $
    text = re.sub(r'\\\((.*?)\\\)', r'$\1$', text, flags=re.DOTALL)
    
    return text

def process_image(image_bytes, max_mb=4):
    """å›¾ç‰‡é¢„å¤„ç†ï¼šä¿®æ­£æ—‹è½¬ + æ™ºèƒ½å‹ç¼©"""
    try:
        img = Image.open(io.BytesIO(image_bytes))
        img = ImageOps.exif_transpose(img) # ä¿®æ­£æ‰‹æœºæ‹ç…§æ—‹è½¬
        
        # ä¿®å¤é€æ˜åº•å˜é»‘
        if img.mode != 'RGB':
            bg = Image.new('RGB', img.size, (255, 255, 255))
            if 'A' in img.mode or 'transparency' in img.info:
                img = img.convert('RGBA')
                bg.paste(img, mask=img.split()[-1])
                img = bg
            else:
                img = img.convert('RGB')

        # å‹ç¼©é€»è¾‘
        buf = io.BytesIO()
        img.save(buf, format="JPEG", quality=95)
        
        # åªæœ‰åœ¨å›¾ç‰‡çœŸçš„å¾ˆå¤§ (>4MB) æ—¶æ‰å‹ç¼©
        if len(buf.getvalue()) > max_mb * 1024 * 1024:
            img.save(buf, format="JPEG", quality=85) 
            
        return buf.getvalue()
    except Exception as e:
        st.error(f"å›¾ç‰‡å¤„ç†å‡ºé”™: {e}")
        return image_bytes

def get_ocr_text(image_bytes):
    """è°ƒç”¨ OCRï¼ŒåŠ å…¥ JSON ç¦ç”¨æç¤º"""
    # ä½¿ç”¨ç¡…åŸºæµåŠ¨ Key
    client = OpenAI(api_key=OCR_API_KEY, base_url="https://api.siliconflow.cn/v1")

    try:
        b64_str = base64.b64encode(image_bytes).decode('utf-8')
        
        # æç¤ºè¯ï¼šæ˜ç¡®è¦æ±‚ä¸è¦è¾“å‡º JSON
        prompt_text = "æå–å›¾ä¸­æ‰€æœ‰æ–‡å­—å’Œå…¬å¼ã€‚è¯·ç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬å†…å®¹ï¼Œä¸è¦è¾“å‡º JSON æ ¼å¼ï¼Œä¸è¦ä½¿ç”¨ä»£ç å—åŒ…è£¹ã€‚"
        
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-OCR",
            messages=[
                {
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": prompt_text},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{b64_str}",
                                "detail": "high" # å¼ºåˆ¶é«˜æ¸…
                            }
                        }
                    ]
                }
            ],
            temperature=0.0, # ä¸¥è°¨æ¨¡å¼
            max_tokens=4096
        )
        
        raw_content = response.choices[0].message.content
        return clean_text(raw_content)

    except Exception as e:
        st.error(f"OCR è¯·æ±‚å¤±è´¥: {e}")
        return None

def ai_stream(history):
    """è°ƒç”¨å¯¹è¯æ¨¡å‹"""
    # ä½¿ç”¨ DeepSeek Key
    client = OpenAI(api_key=CHAT_API_KEY, base_url="https://api.deepseek.com")
    
    # æ¸…æ´—å†å²æ¶ˆæ¯ï¼Œåªä¿ç•™æ–‡æœ¬
    clean_history = []
    for msg in history:
        clean_history.append({"role": msg["role"], "content": str(msg["content"])})

    return client.chat.completions.create(
        model="deepseek-chat",
        messages=clean_history,
        stream=True,
        temperature=0.7
    )

# ================= ç½‘é¡µä¸»ç¨‹åº =================

st.set_page_config(page_title="AI é¢˜ç›®è®²è§£", layout="centered")
st.title("ğŸ“ AI é¢˜ç›®è®²è§£åŠ©æ‰‹")

if "history" not in st.session_state:
    st.session_state.history = []
if "last_file_id" not in st.session_state:
    st.session_state.last_file_id = None

uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šä¼ é¢˜ç›®å›¾ç‰‡", type=['jpg', 'png', 'jpeg'])

if uploaded_file:
    file_id = f"{uploaded_file.name}-{uploaded_file.size}"
    
    # æ–°å›¾ç‰‡å¤„ç†æµç¨‹
    if st.session_state.last_file_id != file_id:
        st.session_state.last_file_id = file_id
        st.session_state.history = []
        
        with st.status("ğŸš€ æ­£åœ¨è¯†åˆ«é¢˜ç›®...", expanded=True) as status:
            # 1. å¤„ç†å›¾ç‰‡
            img_bytes = process_image(uploaded_file.getvalue())
            # 2. è¯†åˆ«æ–‡å­—
            ocr_result = get_ocr_text(img_bytes)
            
            if ocr_result:
                status.update(label="è¯†åˆ«æˆåŠŸï¼", state="complete", expanded=False)
                
                # åˆå§‹åŒ–å¯¹è¯
                sys_msg = "ä½ æ˜¯ä¸€ä½è€å¸ˆã€‚è¯·è§£æé¢˜ç›®æ€è·¯ï¼Œå…¬å¼ä½¿ç”¨LaTeXæ ¼å¼($...$ æˆ– $$...$$)ã€‚"
                user_msg = f"é¢˜ç›®å†…å®¹å¦‚ä¸‹ï¼š\n{ocr_result}\n\nè¯·è®²è§£ã€‚"
                
                st.session_state.history = [
                    {"role": "system", "content": sys_msg},
                    {"role": "user", "content": user_msg}
                ]
                
                # è‡ªåŠ¨è§¦å‘è®²è§£
                with st.chat_message("assistant"):
                    ph = st.empty()
                    full_text = ""
                    try:
                        for chunk in ai_stream(st.session_state.history):
                            if chunk.choices[0].delta.content:
                                full_text += chunk.choices[0].delta.content
                                ph.markdown(clean_text(full_text) + "â–Œ")
                        ph.markdown(clean_text(full_text))
                        st.session_state.history.append({"role": "assistant", "content": full_text})
                    except Exception as e:
                        st.error(f"è®²è§£å‡ºé”™: {e}")
            else:
                status.update(label="è¯†åˆ«å¤±è´¥", state="error")

# æ˜¾ç¤ºå†å²å¯¹è¯
for msg in st.session_state.history:
    if msg["role"] != "system":
        # å¦‚æœæ˜¯ç¬¬ä¸€æ¡é¢˜ç›®å†…å®¹ï¼ŒæŠ˜å æ˜¾ç¤º
        if "é¢˜ç›®å†…å®¹å¦‚ä¸‹" in str(msg["content"]) and msg["role"] == "user":
            with st.expander("æŸ¥çœ‹è¯†åˆ«åˆ°çš„é¢˜ç›®"):
                st.markdown(clean_text(msg["content"]))
            continue
            
        with st.chat_message(msg["role"]):
            st.markdown(clean_text(msg["content"]))

# è¾“å…¥æ¡†
if query := st.chat_input("å“ªé‡Œä¸æ‡‚ï¼Ÿ"):
    with st.chat_message("user"):
        st.markdown(query)
    st.session_state.history.append({"role": "user", "content": query})
    
    with st.chat_message("assistant"):
        ph = st.empty()
        full_text = ""
        try:
            for chunk in ai_stream(st.session_state.history):
                if chunk.choices[0].delta.content:
                    full_text += chunk.choices[0].delta.content
                    ph.markdown(clean_text(full_text) + "â–Œ")
            ph.markdown(clean_text(full_text))
            st.session_state.history.append({"role": "assistant", "content": full_text})
        except Exception as e:
            st.error(f"å‡ºé”™: {e}")
