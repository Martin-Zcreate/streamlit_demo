import streamlit as st
import base64
import io  # æ–°å¢ï¼šç”¨äºå¤„ç†å†…å­˜ä¸­çš„äºŒè¿›åˆ¶æµ
from openai import OpenAI
from PIL import Image, ImageOps # æ–°å¢ï¼šç”¨äºå›¾ç‰‡å‹ç¼©å’Œæ—‹è½¬å¤„ç†

# ================= æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

# å›¾ç‰‡è½¬ Base64 (æœ¬åœ°æ–‡ä»¶ç”¨ï¼Œç›®å‰ä¸»æµç¨‹æ²¡ç”¨åˆ°ï¼Œä¿ç•™)
def get_img_str(file_path):
    with open(file_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

# OCR è¯†åˆ«å‡½æ•° (æ ¸å¿ƒä¿®æ”¹åœ¨è¿™é‡Œ)
@st.cache_data(show_spinner=False)
def get_ocr_text(file_content):
    # ä½ çš„ SiliconFlow API Key
    a = "sk-vogujjwsiclsbtlaorwvnncwfidlxavtukoxcqlciakmhtkr"
    b = "deepseek-ai/DeepSeek-OCR"
    
    client = OpenAI(
        api_key=a,
        base_url="https://api.siliconflow.cn/v1"
    )

    try:
        # ----------------- å›¾ç‰‡é¢„å¤„ç†å¼€å§‹ -----------------
        # 1. è¯»å–äºŒè¿›åˆ¶æ•°æ®ä¸ºå›¾ç‰‡å¯¹è±¡
        image = Image.open(io.BytesIO(file_content))
        
        # 2. ã€å…³é”®ã€‘ä¿®å¤æ‰‹æœºæ‹ç…§çš„æ–¹å‘é—®é¢˜ (æŠŠæ¨ªç€çš„å›¾æ‰¶æ­£)
        image = ImageOps.exif_transpose(image)
        
        # 3. é™åˆ¶æœ€å¤§å°ºå¯¸ (é˜²æ­¢ 4000px å¤§å›¾ç›´æ¥ä¼ ï¼Œé™åˆ¶åˆ° 1024px å¤Ÿç”¨äº†)
        max_size = 1024
        if max(image.size) > max_size:
            image.thumbnail((max_size, max_size))
            
        # 4. è½¬ä¸º RGB æ¨¡å¼ (é˜²æ­¢ PNG é€æ˜åº•å¯¼è‡´æŠ¥é”™)
        if image.mode in ("RGBA", "P"):
            image = image.convert("RGB")
            
        # 5. å‹ç¼©å›¾ç‰‡è´¨é‡ (quality=60 èƒ½æå¤§å‡å°ä½“ç§¯ï¼Œé˜²æ­¢ API æŠ¥é”™)
        buffer = io.BytesIO()
        image.save(buffer, format="JPEG", quality=60)
        
        # 6. è·å–å‹ç¼©åçš„ Base64
        d = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        print(f"åŸå›¾: {len(file_content)/1024:.1f}KB -> å‹ç¼©å: {len(buffer.getvalue())/1024:.1f}KB")
        # ----------------- å›¾ç‰‡é¢„å¤„ç†ç»“æŸ -----------------

        print(f"æ­£åœ¨å‘é€è¯·æ±‚ç»™æ¨¡å‹: {b} ...")

        # å‘é€è¯·æ±‚
        e = client.chat.completions.create(
            model=b,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¯·æå–å›¾ç‰‡ä¸­çš„æ–‡å­—å’Œæ•°å­¦å…¬å¼ã€‚é‡è¦è¦æ±‚ï¼š\n1. æ‰€æœ‰æ•°å­¦å…¬å¼ï¼ˆåŒ…æ‹¬ç®€å•çš„å˜é‡å¦‚x, yï¼‰å¿…é¡»åŒ…å«åœ¨ $ ç¬¦å·ä¸­ï¼ˆè¡Œå†…å…¬å¼ï¼‰æˆ– $$ ç¬¦å·ä¸­ï¼ˆç‹¬ç«‹å…¬å¼ï¼‰ã€‚\n2. ä¸è¦è¾“å‡ºä»»ä½• JSON æ ¼å¼æˆ– Markdown ä»£ç å—ï¼ˆå¦‚ ```jsonï¼‰ã€‚\n3. åªè¿”å›çº¯æ–‡æœ¬å†…å®¹ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{d}"}}
                    ]
                }
            ],
            temperature=0.1,
        )

        content = e.choices[0].message.content
        content = content.strip()
        
        # åå¤„ç†ï¼šå»é™¤ Markdown ä»£ç å—åŒ…è£¹
        if content.startswith("```"):
            lines = content.split('\n')
            if len(lines) >= 2:
                content = "\n".join(lines[1:-1])
        
        # åå¤„ç†ï¼šé˜²æ­¢ JSON æ ¼å¼æ³„éœ²
        if content.endswith("}"):
            start_index = content.find("{")
            if start_index != -1:
                import json
                try:
                    json_data = json.loads(content[start_index:])
                    if isinstance(json_data, dict):
                        for key in ["content", "text", "result", "ocr_text"]:
                            if key in json_data:
                                content = json_data[key]
                                break
                except:
                    pass 
        
        return content

    except Exception as err:
        st.error(f"OCRå‡ºé”™: {err}")
        return None

# AI å¯¹è¯å‡½æ•° (DeepSeek Chat)
def AI(messages):
    # ä½ çš„ DeepSeek å®˜æ–¹ API Key
    client = OpenAI(api_key="sk-af6ba48dbd8a4d1fb0d036551b9bbdc3",
                    base_url="https://api.deepseek.com")
    
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        stream=True
    )
    return response

# ================= ç½‘é¡µç•Œé¢å¸ƒå±€ =================

st.set_page_config(page_title="æ™ºé…·AIä½œä¸šå¸®æ‰‹", page_icon="ğŸ¤–", layout="wide")

# ================= ä¾§è¾¹æ ï¼šåŠŸèƒ½åŒº =================
with st.sidebar:
    st.title("ğŸ› ï¸ å®ç”¨å·¥å…·ç®±")
    
    st.divider()
    
    # åŠŸèƒ½ 1ï¼šé”™é¢˜æœ¬å¯¼å‡º
    st.subheader("ğŸ“š é”™é¢˜æœ¬")
    if st.button("ğŸ“¥ å¯¼å‡ºå½“å‰å¯¹è¯ä¸º Markdown"):
        if st.session_state.messages:
            md_content = f"# é”™é¢˜è®°å½• - {str(st.session_state.current_topic)[:20]}...\n\n"
            md_content += f"## ğŸ“ é¢˜ç›®\n{st.session_state.current_topic}\n\n"
            md_content += "## ğŸ’¡ è®²è§£è¿‡ç¨‹\n"
            for msg in st.session_state.messages:
                if msg["role"] == "assistant":
                    md_content += f"**è€å¸ˆ**: {msg['content']}\n\n"
                elif msg["role"] == "user" and "å­¦ç”Ÿå‘æ¥äº†è¿™é“é¢˜" not in msg['content']:
                    md_content += f"**å­¦ç”Ÿ**: {msg['content']}\n\n"
            
            b64_md = base64.b64encode(md_content.encode()).decode()
            href = f'<a href="data:file/markdown;base64,{b64_md}" download="é”™é¢˜æœ¬.md">ç‚¹å‡»ä¸‹è½½é”™é¢˜è®°å½•</a>'
            st.markdown(href, unsafe_allow_html=True)
        else:
            st.warning("æš‚æ— å¯¹è¯å†…å®¹å¯å¯¼å‡º")

    st.divider()

    # åŠŸèƒ½ 2ï¼šä½œæ–‡è¾…å¯¼
    st.subheader("âœï¸ ä½œæ–‡è¾…å¯¼")
    composition_title = st.text_input("è¾“å…¥ä½œæ–‡é¢˜ç›®ï¼ˆå¦‚ï¼šæˆ‘çš„å‡æœŸï¼‰")
    if st.button("ğŸ“ å¼€å§‹è¾…å¯¼"):
        if composition_title:
            st.session_state.messages = [
                {"role": "system", "content": """
                ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ä½œæ–‡è¾…å¯¼è€å¸ˆã€‚
                1. é¦–å…ˆå¼•å¯¼å­¦ç”Ÿè¿›è¡Œå¤´è„‘é£æš´ï¼Œåˆ—å‡ºå†™ä½œå¤§çº²ã€‚
                2. æ•™æˆå†™ä½œæŠ€å·§ï¼ˆå¦‚ï¼šå¦‚ä½•å¼€å¤´ã€å¦‚ä½•æå†™ç»†èŠ‚ï¼‰ã€‚
                3. é¼“åŠ±å­¦ç”Ÿåˆ†æ®µå†™ä½œï¼Œå¹¶ç»™å‡ºå³æ—¶åé¦ˆã€‚
                4. æœ€åç»™å‡ºä¸€ç¯‡é«˜è´¨é‡çš„èŒƒæ–‡ä½œä¸ºå‚è€ƒã€‚
                """}
            ]
            st.session_state.current_topic = f"ä½œæ–‡é¢˜ç›®ï¼š{composition_title}"
            user_msg = f"è€å¸ˆï¼Œæˆ‘è¦å†™ä¸€ç¯‡å…³äºã€Š{composition_title}ã€‹çš„ä½œæ–‡ï¼Œè¯·æ•™æ•™æˆ‘æ€ä¹ˆå†™ã€‚"
            st.session_state.messages.append({"role": "user", "content": user_msg})
            st.session_state.need_first_response = True
            st.rerun()

    st.divider()

    # åŠŸèƒ½ 3ï¼šçŸ¥è¯†ç‚¹ç™¾ç§‘
    st.subheader("ğŸ“– çŸ¥è¯†ç‚¹ç™¾ç§‘")
    concept = st.text_input("è¾“å…¥æƒ³æŸ¥è¯¢çš„æ¦‚å¿µï¼ˆå¦‚ï¼šç‰›é¡¿ç¬¬äºŒå®šå¾‹ï¼‰")
    if st.button("ğŸ” æŸ¥è¯¢è®²è§£"):
        if concept:
            st.session_state.messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åšå­¦çš„ç™¾ç§‘è€å¸ˆã€‚è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæ¦‚å¿µï¼Œå¹¶ä¸¾å‡ºç”Ÿæ´»ä¸­çš„ä¾‹å­ã€‚"}
            ]
            st.session_state.current_topic = f"æŸ¥è¯¢æ¦‚å¿µï¼š{concept}"
            user_msg = f"è¯·è¯¦ç»†è®²è§£ä¸€ä¸‹ã€{concept}ã€‘è¿™ä¸ªçŸ¥è¯†ç‚¹ã€‚"
            st.session_state.messages.append({"role": "user", "content": user_msg})
            st.session_state.need_first_response = True
            st.rerun()

# ================= ä¸»ç•Œé¢ =================
st.title("ğŸ¤–æ™ºé…·AIä½œä¸šå¸®æ‰‹")

# åˆå§‹åŒ– Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_topic" not in st.session_state:
    st.session_state.current_topic = None
if "last_uploaded_file_id" not in st.session_state:
    st.session_state.last_uploaded_file_id = None
if "need_first_response" not in st.session_state:
    st.session_state.need_first_response = False

st.markdown("""
<style>
div[data-testid="stFileUploader"] label {
    font-size: 1.1rem !important;
    font-weight: bold !important;
}
</style>
""", unsafe_allow_html=True)

# 1. ä¸Šä¼ /æ‹æ‘„æ¨¡å—
img_file = st.file_uploader(
    "ğŸ“¸ ç‚¹å‡»æ‹æ‘„é¢˜ç›® (æˆ–åœ¨å·¦ä¾§é€‰æ‹©å…¶ä»–åŠŸèƒ½)", 
    type=['jpg', 'png', 'jpeg'], 
    accept_multiple_files=False,
    key="uploader"
)

# å¤„ç†å›¾ç‰‡ä¸Šä¼ é€»è¾‘
if img_file:
    file_content = img_file.getvalue()
    file_id = f"{img_file.name}_{img_file.size}"
    
    if file_id != st.session_state.last_uploaded_file_id:
        with st.spinner('æ­£åœ¨å¤„ç†å›¾ç‰‡å¹¶è¯†åˆ«é¢˜ç›®...'):
            # è°ƒç”¨å¸¦å‹ç¼©åŠŸèƒ½çš„ OCR å‡½æ•°
            ocr_result = get_ocr_text(file_content)
            
            if ocr_result:
                st.session_state.current_topic = ocr_result
                st.session_state.last_uploaded_file_id = file_id
                
                # åˆå§‹åŒ–æ–°çš„å¯¹è¯
                st.session_state.messages = [
                    {"role": "system", "content": """
                    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è€å¸ˆã€‚
                    1. å½“å­¦ç”Ÿé—®é—®é¢˜æ—¶ï¼Œä¸è¦ç›´æ¥ç»™å®Œæ•´ç­”æ¡ˆã€‚
                    2. è¯·ä½¿ç”¨"éš¾åº¦é™çº§"æ³•ï¼ŒæŠŠå¤æ‚çš„é¢˜ç›®æ‹†è§£æˆç®€å•çš„æ­¥éª¤ã€‚
                    3. å…ˆè§£é‡Šæ€è·¯ï¼Œå†è®©å­¦ç”Ÿå»æ€è€ƒé—®é¢˜ã€‚
                    4. å…¬å¼è¯·ä½¿ç”¨ LaTeX æ ¼å¼ï¼Œè¡Œå†…å…¬å¼ç”¨ $ åŒ…è£¹ï¼Œç‹¬ç«‹å…¬å¼ç”¨ $$ åŒ…è£¹ã€‚
                    """},
                    {"role": "user", "content": f"å­¦ç”Ÿå‘æ¥äº†è¿™é“é¢˜ï¼Œè¯·è®²è§£ï¼š\n{ocr_result}"}
                ]
                
                st.session_state.need_first_response = True
                st.rerun()

# 2. æ˜¾ç¤ºè¯†åˆ«åˆ°çš„é¢˜ç›®
if st.session_state.current_topic:
    with st.expander("ğŸ“ æŸ¥çœ‹è¯†åˆ«åˆ°çš„é¢˜ç›®", expanded=True):
        st.markdown(st.session_state.current_topic)

# 3. èŠå¤©ç•Œé¢
st.subheader("ğŸ‘¨â€ğŸ« è€å¸ˆè®²è§£ & ç­”ç–‘")

for msg in st.session_state.messages:
    if msg["role"] == "system":
        continue
    if msg["role"] == "user" and "å­¦ç”Ÿå‘æ¥äº†è¿™é“é¢˜" in msg["content"]:
        continue 
        
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# å¤„ç†é¦–æ¬¡è‡ªåŠ¨å›å¤
if st.session_state.need_first_response:
    st.session_state.need_first_response = False
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        stream = AI(st.session_state.messages)
        for chunk in stream:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})
    st.rerun()

# åº•éƒ¨è¾“å…¥æ¡†
if prompt := st.chat_input("å“ªé‡Œä¸æ‡‚ï¼Ÿå¯ä»¥ç»§ç»­é—®è€å¸ˆ..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        stream = AI(st.session_state.messages)
        for chunk in stream:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})
