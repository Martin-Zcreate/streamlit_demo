import streamlit as st
import base64
import re
import io
from PIL import Image, ImageOps  # å¿…é¡»å¼•å…¥ ImageOps å¤„ç†æ‰‹æœºç…§ç‰‡æ—‹è½¬
from openai import OpenAI

# ================= é…ç½®åŒºåŸŸ =================
OCR_KEY = "sk-vogujjwsiclsbtlaorwvnncwfidlxavtukoxcqlciakmhtkr" 
CHAT_KEY = "sk-af6ba48dbd8a4d1fb0d036551b9bbdc3"
# ===========================================

def clean_latex(text):
    """
    æ¸…æ´— LaTeX æ ¼å¼ä»¥ä¾¿ Streamlit æ¸²æŸ“
    """
    if not text:
        return text
    text = re.sub(r'\\\[(.*?)\\\]', r'$$\1$$', text, flags=re.DOTALL)
    text = re.sub(r'\\\((.*?)\\\)', r'$\1$', text, flags=re.DOTALL)
    return text

def compress_image(image_bytes, max_size_kb=1024): # æ”¹å¤§åˆ° 1MB
    """
    å¤„ç†å›¾ç‰‡ï¼šä¿®æ­£æ—‹è½¬ã€ä¿æŒå½©è‰²ã€é€‚åº¦å‹ç¼©
    """
    try:
        img = Image.open(io.BytesIO(image_bytes))
        
        # 1. ä¿®æ­£æ‰‹æœºæ‹ç…§çš„æ—‹è½¬ä¿¡æ¯ (å…³é”®)
        img = ImageOps.exif_transpose(img)
        
        # 2. å¼ºåˆ¶è½¬ä¸º RGBï¼Œé˜²æ­¢ç°åº¦å›¾å¯¼è‡´ OCR è¯†åˆ«ç‡ä¸‹é™ (å…³é”®)
        if img.mode != 'RGB':
            img = img.convert('RGB')

        # å‡†å¤‡è¾“å‡º
        buf = io.BytesIO()
        img.save(buf, format="JPEG", quality=95)
        d = buf.getvalue() # d = data

        # å¦‚æœæœ¬èº«å°±å°äºé™åˆ¶ï¼Œç›´æ¥è¿”å›
        if len(d) <= max_size_kb * 1024:
            return d

        # 3. å¾ªç¯å‹ç¼©é€»è¾‘
        q = 90 # quality
        w, h = img.size
        s = 1.0 # scale
        
        while True:
            buf = io.BytesIO()
            if s < 1.0:
                # ç¼©æ”¾å°ºå¯¸
                nw = int(w * s)
                nh = int(h * s)
                # ä½¿ç”¨ LANCZOS ç®—æ³•ä¿æŒæ–‡å­—è¾¹ç¼˜æ¸…æ™°
                img_r = img.resize((nw, nh), Image.Resampling.LANCZOS)
                img_r.save(buf, format="JPEG", quality=q)
            else:
                img.save(buf, format="JPEG", quality=q)
            
            d = buf.getvalue()
            
            if len(d) <= max_size_kb * 1024:
                return d
            
            # è°ƒæ•´å‚æ•°
            if q > 70:
                q -= 10
            else:
                s *= 0.8
                
            if s < 0.2: # é˜²æ­¢ç¼©å¤ªå°å®Œå…¨çœ‹ä¸æ¸…
                return d

    except Exception as e:
        st.warning(f"å¤„ç†å›¾ç‰‡å‡ºé”™: {e}")
        return image_bytes

def get_ocr_text(image_bytes):
    # ä½¿ç”¨é…ç½®å¥½çš„ Key
    client = OpenAI(
        api_key=OCR_KEY, 
        base_url="https://api.siliconflow.cn/v1"
    )

    try:
        d = base64.b64encode(image_bytes).decode('utf-8')
        
        resp = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-OCR",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¯·æå–å›¾ä¸­æ‰€æœ‰æ–‡å­—å’Œå…¬å¼ã€‚è¡Œå†…å…¬å¼ç”¨ $...$ï¼Œç‹¬ç«‹å…¬å¼ç”¨ $$...$$ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{d}"}}
                    ]
                }
            ],
            temperature=0.1,
        )

        content = resp.choices[0].message.content
        return clean_latex(content)

    except Exception as err:
        st.error(f"OCRè¯·æ±‚å¤±è´¥: {err}")
        return None

def AI_stream(messages):
    client = OpenAI(
        api_key=CHAT_KEY,
        base_url="https://api.deepseek.com"
    )
    
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        stream=True
    )
    return response

# ================= ç½‘é¡µç•Œé¢å¸ƒå±€ =================

st.title("ğŸ¤– AI ä½œä¸šå¸®æ‰‹")
st.write("ç”¨æ‰‹æœºæ‹ä¸‹é¢˜ç›®ï¼ŒAI å¸®ä½ æ‹†è§£æ€è·¯ã€‚")

# åˆå§‹åŒ–çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_id" not in st.session_state:
    st.session_state.last_id = None
if "ocr_res" not in st.session_state:
    st.session_state.ocr_res = None

SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è€å¸ˆã€‚
1. éš¾åº¦é™çº§ï¼šæŠŠå¤æ‚é¢˜ç›®æ‹†è§£æˆç®€å•æ­¥éª¤ã€‚
2. å¼•å¯¼æ€è€ƒï¼šä¸è¦ç›´æ¥ç»™ä»£ç ï¼Œå…ˆè®²æ€è·¯ã€‚
3. æ ¼å¼è§„èŒƒï¼šå…¬å¼ä½¿ç”¨ LaTeXï¼Œè¡Œå†…ç”¨ $ï¼Œç‹¬ç«‹ç”¨ $$ã€‚
"""

img_file = st.file_uploader(
    "ğŸ“¸ ç‚¹å‡»æ‹æ‘„é¢˜ç›®", 
    type=['jpg', 'png', 'jpeg'], 
    key="uploader"
)

if img_file:
    fid = f"{img_file.name}-{img_file.size}"
    
    # æ–°æ–‡ä»¶å¤„ç†
    if st.session_state.last_id != fid:
        st.session_state.last_id = fid
        st.session_state.messages = []
        st.session_state.ocr_res = None
        
        raw_bytes = img_file.getvalue()
        
        # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
        with st.status("æ­£åœ¨å¤„ç†å›¾ç‰‡...", expanded=True) as status:
            st.write("ğŸ”„ æ­£åœ¨ä¿®æ­£æ–¹å‘ä¸ä¼˜åŒ–ä½“ç§¯...")
            # å‹ç¼©å¤„ç†
            proc_bytes = compress_image(raw_bytes, max_size_kb=1024)
            
            st.write("ğŸ” æ­£åœ¨è¯†åˆ«é¢˜ç›®å†…å®¹...")
            # OCR è¯†åˆ«
            st.session_state.ocr_res = get_ocr_text(proc_bytes)
            status.update(label="å¤„ç†å®Œæˆ", state="complete", expanded=False)

    # ç»“æœå±•ç¤ºä¸å¯¹è¯
    if st.session_state.ocr_res:
        txt = st.session_state.ocr_res
        
        st.subheader("ğŸ“ è¯†åˆ«ç»“æœ")
        st.markdown(txt)
        
        st.subheader("ğŸ‘¨â€ğŸ« è€å¸ˆè®²è§£")
        
        # é¦–æ¬¡è‡ªåŠ¨è§¦å‘è®²è§£
        if not st.session_state.messages:
            u_msg = f"é¢˜ç›®å†…å®¹ï¼š\n{txt}\n\nè¯·è®²è§£è¿™é“é¢˜ã€‚"
            st.session_state.messages.append({"role": "user", "content": u_msg})
            
            api_msgs = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages
            
            with st.chat_message("assistant"):
                ph = st.empty()
                full_res = ""
                try:
                    stream = AI_stream(api_msgs)
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            full_res += chunk.choices[0].delta.content
                            ph.markdown(clean_latex(full_res))
                    st.session_state.messages.append({"role": "assistant", "content": full_res})
                except Exception as e:
                    st.error(f"AI å“åº”å‡ºé”™: {e}")

        # æ¸²æŸ“å†å²æ¶ˆæ¯ (è·³è¿‡ç¬¬ä¸€æ¡éšå«çš„ User æ¶ˆæ¯)
        else:
            for i, msg in enumerate(st.session_state.messages):
                if i == 0 and msg["role"] == "user":
                    continue
                with st.chat_message(msg["role"]):
                    st.markdown(clean_latex(msg["content"]))

        # åº•éƒ¨è¾“å…¥æ¡†
        if prompt := st.chat_input("å“ªé‡Œä¸æ‡‚ï¼Ÿç»§ç»­é—®..."):
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

            with st.chat_message("assistant"):
                ph = st.empty()
                full_res = ""
                api_msgs = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages
                
                try:
                    stream = AI_stream(api_msgs)
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            full_res += chunk.choices[0].delta.content
                            ph.markdown(clean_latex(full_res))
                    st.session_state.messages.append({"role": "assistant", "content": full_res})
                except Exception as e:
                    st.error(f"AI å“åº”å‡ºé”™: {e}")
