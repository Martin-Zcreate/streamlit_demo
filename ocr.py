import streamlit as st
import base64
from openai import OpenAI
from PIL import Image

def get_img_str(file_path):
    with open(file_path, "rb") as f:
        return base64.b64encode(f.read()).decode('utf-8')

def get_ocr_text(uploaded_file):
    a = "sk-vogujjwsiclsbtlaorwvnncwfidlxavtukoxcqlciakmhtkr"
    b = "deepseek-ai/DeepSeek-OCR"
    
    # å»ºç«‹è¿æ¥ (å·²ä¿®å¤URLæ ¼å¼)
    client = OpenAI(
        api_key=a,
        base_url="https://api.siliconflow.cn/v1"
    )

    try:
        # è¯»å–å›¾ç‰‡å¹¶è½¬ä¸º Base64
        c = uploaded_file.getvalue()
        d = base64.b64encode(c).decode('utf-8')
        
        print(f"æ­£åœ¨å‘é€è¯·æ±‚ç»™æ¨¡å‹: {b} ...")

        e = client.chat.completions.create(
            model=b,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¯·å°†è¿™å¼ å›¾ç‰‡é‡Œçš„æ‰€æœ‰æ–‡å­—å’Œæ•°å­¦å…¬å¼æå–å‡ºæ¥ï¼Œå…¬å¼è¯·ä½¿ç”¨ LaTeX æ ¼å¼ã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{d}"}}
                    ]
                }
            ],
            temperature=0.1,
        )
        return e.choices[0].message.content

    except Exception as err:
        st.error(f"OCRå‡ºé”™: {err}")
        return None

def AI(question_text):
    # å»ºç«‹è¿æ¥ (å·²ä¿®å¤URLæ ¼å¼)
    client = OpenAI(api_key="sk-af6ba48dbd8a4d1fb0d036551b9bbdc3",
                    base_url="https://api.deepseek.com")
    
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": 
             """
              ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è€å¸ˆã€‚
              1. å½“å­¦ç”Ÿé—®é—®é¢˜æ—¶ï¼Œä¸è¦ç›´æ¥ç»™å®Œæ•´ç­”æ¡ˆã€‚
              2. è¯·ä½¿ç”¨"éš¾åº¦é™çº§"æ³•ï¼ŒæŠŠå¤æ‚çš„é¢˜ç›®æ‹†è§£æˆç®€å•çš„æ­¥éª¤ã€‚
              3. å…ˆè§£é‡Šæ€è·¯ï¼Œå†è®©å­¦ç”Ÿå»æ€è€ƒé—®é¢˜ã€‚
              4. å…¬å¼è¯·ä½¿ç”¨markdownæ ¼å¼ã€‚
             """
             },
            {"role": "user", "content": f"å­¦ç”Ÿå‘æ¥äº†è¿™é“é¢˜ï¼Œè¯·è®²è§£ï¼š\n{question_text}"},
        ],
        stream=True
    )
    return response

# ================= ç½‘é¡µç•Œé¢å¸ƒå±€ =================

st.title("ğŸ¤–æ™ºé…·AIä½œä¸šå¸®æ‰‹")

# æ ¸å¿ƒä¿®æ”¹ï¼šä¼˜å…ˆå±•ç¤ºæ‘„åƒå¤´è¾“å…¥
method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["ğŸ“¸ æ‹ç…§", "ğŸ“¤ ä¸Šä¼ å›¾ç‰‡"], horizontal=True)

img_file = None

if method == "ğŸ“¸ æ‹ç…§":
    # camera_input ä¼šåœ¨ç§»åŠ¨ç«¯æµè§ˆå™¨è¯·æ±‚æ‘„åƒå¤´æƒé™å¹¶ç›´æ¥æ˜¾ç¤ºç”»é¢
    img_file = st.camera_input("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®æ‹ç…§")
else:
    img_file = st.file_uploader(
        "é€‰æ‹©ä½œä¸šå›¾ç‰‡", 
        type=['jpg', 'png', 'jpeg'], 
        accept_multiple_files=False
    )

if img_file:
    with st.spinner('æ­£åœ¨è¯†åˆ«é¢˜ç›®...'):
        f = get_ocr_text(img_file)

    if f:
        st.subheader("ğŸ“ è¯†åˆ«åˆ°çš„é¢˜ç›®")
        st.info(f)
        
        st.subheader("ğŸ‘¨â€ğŸ« è€å¸ˆè®²è§£")
        result_area = st.empty()
        
        g = AI(f)
        
        full_response = ""
        for chunk in g:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                result_area.markdown(full_response)
